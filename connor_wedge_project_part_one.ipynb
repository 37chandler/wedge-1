{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8452e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_gbq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d6a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns in pandas data frame\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0caee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish pathway to Google BigQuery (GBQ) account\n",
    "\n",
    "service_path = \"/Users/Owner/Google Drive/MSBA/Classes/bmkt_670_applied_data_analytics/gbq_key/\"\n",
    "service_file = 'evident-catcher-327918-fa366e7e71f5.json'\n",
    "gbq_proj_id = 'evident-catcher-327918'\n",
    "gbq_dataset_id = 'wedge_master'\n",
    "\n",
    "private_key = service_path + service_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e157d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)\n",
    "\n",
    "# Creat client to connect with GBQ\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abcf91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a list of folders in the main .zip file\n",
    "# Just for reference\n",
    "\n",
    "location = 'WedgeZipOfZips.zip'\n",
    "\n",
    "with zipfile.ZipFile(location) as z:\n",
    "    # Create list of all folders in zip file\n",
    "    fold_list = z.namelist()\n",
    "\n",
    "fold_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2709cdea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transArchive_201001_201003.zip/transArchive_201001_201003.csv\n",
      "transArchive_201004_201006.zip/transArchive_201004_201006.csv\n",
      "transArchive_201007_201009.zip/transArchive_201007_201009.csv\n",
      "transArchive_201010_201012.zip/transArchive_201010_201012.csv\n",
      "transArchive_201101_201103.zip/transArchive_201101_201103.csv\n",
      "transArchive_201104.zip/transArchive_201104.csv\n",
      "transArchive_201105.zip/transArchive_201105.csv\n",
      "transArchive_201106.zip/transArchive_201106.csv\n",
      "transArchive_201107_201109.zip/transArchive_201107_201109.csv\n",
      "transArchive_201110_201112.zip/transArchive_201110_201112.csv\n",
      "transArchive_201201_201203.zip/transArchive_201201_201203.csv\n",
      "transArchive_201201_201203_inactive.zip/transArchive_201201_201203_inactive.csv\n",
      "transArchive_201204_201206.zip/transArchive_201204_201206.csv\n",
      "transArchive_201204_201206_inactive.zip/transArchive_201204_201206_inactive.csv\n",
      "transArchive_201207_201209.zip/transArchive_201207_201209.csv\n",
      "transArchive_201207_201209_inactive.zip/transArchive_201207_201209_inactive.csv\n",
      "transArchive_201210_201212.zip/transArchive_201210_201212.csv\n",
      "transArchive_201210_201212_inactive.zip/transArchive_201210_201212_inactive.csv\n",
      "transArchive_201301_201303.zip/transArchive_201301_201303.csv\n",
      "transArchive_201301_201303_inactive.zip/transArchive_201301_201303_inactive.csv\n",
      "transArchive_201304_201306.zip/transArchive_201304_201306.csv\n",
      "transArchive_201304_201306_inactive.zip/transArchive_201304_201306_inactive.csv\n",
      "transArchive_201307_201309.zip/transArchive_201307_201309.csv\n",
      "transArchive_201307_201309_inactive.zip/transArchive_201307_201309_inactive.csv\n",
      "transArchive_201310_201312.zip/transArchive_201310_201312.csv\n",
      "transArchive_201310_201312_inactive.zip/transArchive_201310_201312_inactive.csv\n",
      "transArchive_201401_201403.zip/transArchive_201401_201403.csv\n",
      "transArchive_201401_201403_inactive.zip/transArchive_201401_201403_inactive.csv\n",
      "transArchive_201404_201406.zip/transArchive_201404_201406.csv\n",
      "transArchive_201404_201406_inactive.zip/transArchive_201404_201406_inactive.csv\n",
      "transArchive_201407_201409.zip/transArchive_201407_201409.csv\n",
      "transArchive_201407_201409_inactive.zip/transArchive_201407_201409_inactive.csv\n",
      "transArchive_201410_201412.zip/transArchive_201410_201412.csv\n",
      "transArchive_201410_201412_inactive.zip/transArchive_201410_201412_inactive.csv\n",
      "transArchive_201501_201503.zip/transArchive_201501_201503.csv\n",
      "transArchive_201504_201506.zip/transArchive_201504_201506.csv\n",
      "transArchive_201507_201509.zip/transArchive_201507_201509.csv\n",
      "transArchive_201510.zip/transArchive_201510.csv\n",
      "transArchive_201511.zip/transArchive_201511.csv\n",
      "transArchive_201512.zip/transArchive_201512.csv\n",
      "transArchive_201601.zip/transArchive_201601.csv\n",
      "transArchive_201602.zip/transArchive_201602.csv\n",
      "transArchive_201603.zip/transArchive_201603.csv\n",
      "transArchive_201604.zip/transArchive_201604.csv\n",
      "transArchive_201605.zip/transArchive_201605.csv\n",
      "transArchive_201606.zip/transArchive_201606.csv\n",
      "transArchive_201607.zip/transArchive_201607.csv\n",
      "transArchive_201608.zip/transArchive_201608.csv\n",
      "transArchive_201609.zip/transArchive_201609.csv\n",
      "transArchive_201610.zip/transArchive_201610.csv\n",
      "transArchive_201611.zip/transArchive_201611.csv\n",
      "transArchive_201612.zip/transArchive_201612.csv\n",
      "transArchive_201701.zip/transArchive_201701.csv\n"
     ]
    }
   ],
   "source": [
    "# Confirming that there is only one .csv in each .zip\n",
    "# Code adapted from here:\n",
    "# https://unix.stackexchange.com/questions/239898/listing-files-from-nested-zip-files-without-extracting\n",
    "\n",
    "location = 'WedgeZipOfZips.zip'\n",
    "\n",
    "def uz(f, parent=[]):\n",
    "\n",
    "    result = []\n",
    "    try:\n",
    "        zf = zipfile.ZipFile(f)\n",
    "        for e in zf.namelist():\n",
    "            path=parent+[e]\n",
    "            if e.lower().endswith(\".zip\"):\n",
    "                result += uz(io.BytesIO(zf.open(e).read()), path)\n",
    "            else:\n",
    "                result.append(\"/\".join(path))\n",
    "\n",
    "    except Exception as ex:\n",
    "        return result\n",
    "\n",
    "    return result\n",
    "\n",
    "print(\"\\n\".join(uz(open(location, \"rb\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bf5d2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all file paths\n",
    "# Ended up not being needed, but preserved for posterity\n",
    "\n",
    "file_ext_list = uz(open(location, \"rb\"))\n",
    "\n",
    "full_ext_list = []\n",
    "\n",
    "for name in file_ext_list:\n",
    "    full_ext_list.append(location + \"/\"+ name)\n",
    "\n",
    "full_ext_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8205dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the schema of columns and variable types for the tables in GBQ\n",
    "\n",
    "wedge_schema = [{\"name\": \"datetime\", \"type\": \"TIMESTAMP\"},\n",
    "{\"name\": \"register_no\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"emp_no\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"trans_no\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"upc\", \"type\": \"STRING\"},\n",
    "{\"name\": \"description\", \"type\": \"STRING\"},\n",
    "{\"name\": \"trans_type\", \"type\": \"STRING\"},\n",
    "{\"name\": \"trans_subtype\", \"type\": \"STRING\"},\n",
    "{\"name\": \"trans_status\", \"type\": \"STRING\"},\n",
    "{\"name\": \"department\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"quantity\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"Scale\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"cost\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"unitPrice\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"total\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"regPrice\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"altPrice\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"tax\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"taxexempt\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"foodstamp\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"wicable\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"discount\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"memDiscount\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"discountable\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"discounttype\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"voided\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"percentDiscount\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"ItemQtty\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"volDiscType\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"volume\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"VolSpecial\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"mixMatch\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"matched\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"memType\", \"type\": \"BOOLEAN\"},\n",
    "{\"name\": \"staff\", \"type\": \"BOOLEAN\"},\n",
    "{\"name\": \"numflag\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"itemstatus\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"tenderstatus\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"charflag\", \"type\": \"STRING\"},\n",
    "{\"name\": \"varflag\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"batchHeaderID\", \"type\": \"BOOLEAN\"},\n",
    "{\"name\": \"local\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"organic\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"display\", \"type\": \"BOOLEAN\"},\n",
    "{\"name\": \"receipt\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"card_no\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"store\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"branch\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"match_id\", \"type\": \"FLOAT\"},\n",
    "{\"name\": \"trans_id\", \"type\": \"FLOAT\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30926d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on transArchive_201001_201003.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [10:45, 107.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201001_201003.csv.\n",
      "Starting on transArchive_201004_201006.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [12:10, 104.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201004_201006.csv.\n",
      "Starting on transArchive_201007_201009.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [11:15, 112.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201007_201009.csv.\n",
      "Starting on transArchive_201010_201012.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "6it [11:20, 113.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201010_201012.csv.\n",
      "Starting on transArchive_201101_201103.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [11:15, 112.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201101_201103.csv.\n",
      "Starting on transArchive_201104.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [04:00, 80.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201104.csv.\n",
      "Starting on transArchive_201105.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [03:57, 79.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201105.csv.\n",
      "Starting on transArchive_201106.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:49, 114.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201106.csv.\n",
      "Starting on transArchive_201107_201109.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [11:16, 96.63s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201107_201109.csv.\n",
      "Starting on transArchive_201110_201112.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [11:39, 99.87s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201110_201112.csv.\n",
      "Starting on transArchive_201201_201203.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [11:55, 119.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201201_201203.csv.\n",
      "Starting on transArchive_201201_201203_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "1it [00:57, 57.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201201_201203_inactive.csv.\n",
      "Starting on transArchive_201204_201206.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "7it [11:46, 100.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201204_201206.csv.\n",
      "Starting on transArchive_201204_201206_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:56, 56.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201204_201206_inactive.csv.\n",
      "Starting on transArchive_201207_201209.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [10:51, 108.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201207_201209.csv.\n",
      "Starting on transArchive_201207_201209_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (33,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "1it [00:59, 59.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201207_201209_inactive.csv.\n",
      "Starting on transArchive_201210_201212.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [12:08, 121.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201210_201212.csv.\n",
      "Starting on transArchive_201210_201212_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:52, 52.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201210_201212_inactive.csv.\n",
      "Starting on transArchive_201301_201303.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [11:17, 112.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201301_201303.csv.\n",
      "Starting on transArchive_201301_201303_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:35, 35.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201301_201303_inactive.csv.\n",
      "Starting on transArchive_201304_201306.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [12:36, 108.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201304_201306.csv.\n",
      "Starting on transArchive_201304_201306_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:33, 33.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201304_201306_inactive.csv.\n",
      "Starting on transArchive_201307_201309.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [11:19, 113.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201307_201309.csv.\n",
      "Starting on transArchive_201307_201309_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:55, 55.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201307_201309_inactive.csv.\n",
      "Starting on transArchive_201310_201312.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (33,43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "6it [10:52, 108.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201310_201312.csv.\n",
      "Starting on transArchive_201310_201312_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:21, 21.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201310_201312_inactive.csv.\n",
      "Starting on transArchive_201401_201403.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [11:38, 116.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201401_201403.csv.\n",
      "Starting on transArchive_201401_201403_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:14, 14.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201401_201403_inactive.csv.\n",
      "Starting on transArchive_201404_201406.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [12:08, 104.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201404_201406.csv.\n",
      "Starting on transArchive_201404_201406_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:15, 15.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201404_201406_inactive.csv.\n",
      "Starting on transArchive_201407_201409.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [12:00, 102.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201407_201409.csv.\n",
      "Starting on transArchive_201407_201409_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:20, 20.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201407_201409_inactive.csv.\n",
      "Starting on transArchive_201410_201412.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [11:51, 118.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201410_201412.csv.\n",
      "Starting on transArchive_201410_201412_inactive.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201410_201412_inactive.csv.\n",
      "Starting on transArchive_201501_201503.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [11:58, 102.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201501_201503.csv.\n",
      "Starting on transArchive_201504_201506.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [11:58, 102.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201504_201506.csv.\n",
      "Starting on transArchive_201507_201509.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [11:53, 101.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201507_201509.csv.\n",
      "Starting on transArchive_201510.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [04:08, 82.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201510.csv.\n",
      "Starting on transArchive_201511.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (18,36,37,41,43,44,48) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "2it [03:25, 102.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201511.csv.\n",
      "Starting on transArchive_201512.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:34, 107.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201512.csv.\n",
      "Starting on transArchive_201601.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:28, 104.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201601.csv.\n",
      "Starting on transArchive_201602.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:08, 94.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201602.csv.\n",
      "Starting on transArchive_201603.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:26, 103.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201603.csv.\n",
      "Starting on transArchive_201604.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:10, 95.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201604.csv.\n",
      "Starting on transArchive_201605.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:19, 99.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201605.csv.\n",
      "Starting on transArchive_201606.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:11, 95.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201606.csv.\n",
      "Starting on transArchive_201607.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:24, 102.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201607.csv.\n",
      "Starting on transArchive_201608.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:08, 94.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201608.csv.\n",
      "Starting on transArchive_201609.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:05, 92.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201609.csv.\n",
      "Starting on transArchive_201610.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:36, 108.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201610.csv.\n",
      "Starting on transArchive_201611.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:17, 98.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201611.csv.\n",
      "Starting on transArchive_201612.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:45, 112.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201612.csv.\n",
      "Starting on transArchive_201701.zip.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [03:47, 113.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with transArchive_201701.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean each .csv, convert it to pandas data frame, and upload data frame to GBQ\n",
    "\n",
    "# The name of the main .zip file in which all of the sub-zip files reside\n",
    "location = 'WedgeZipOfZips.zip'\n",
    "\n",
    "# Each dataframe has these standardized column names assigned to them below, even if they already have headers\n",
    "col_heads = [\"datetime\", \"register_no\", \"emp_no\", \"trans_no\", \"upc\", \"description\", \n",
    "             \"trans_type\", \"trans_subtype\", \"trans_status\", \"department\", \"quantity\", \n",
    "             \"Scale\", \"cost\", \"unitPrice\", \"total\", \"regPrice\", \"altPrice\", \"tax\", \n",
    "             \"taxexempt\", \"foodstamp\", \"wicable\", \"discount\", \"memDiscount\", \"discountable\", \n",
    "             \"discounttype\", \"voided\", \"percentDiscount\", \"ItemQtty\", \"volDiscType\", \n",
    "             \"volume\", \"VolSpecial\", \"mixMatch\", \"matched\", \"memType\", \"staff\", \"numflag\", \n",
    "             \"itemstatus\", \"tenderstatus\", \"charflag\", \"varflag\", \"batchHeaderID\", \n",
    "             \"local\", \"organic\", \"display\", \"receipt\", \"card_no\", \"store\", \"branch\", \n",
    "             \"match_id\", \"trans_id\"]\n",
    "\n",
    "# Open main zip file\n",
    "with zipfile.ZipFile(location) as z:\n",
    "    # Create list of all folders in zip file\n",
    "    fold_list = z.namelist()\n",
    "    # Loop through each file in zip\n",
    "    for name in fold_list:\n",
    "        # Print .zip name to display which file is currently in progress for monitoring purposes\n",
    "        print(f\"Starting on {name}.\")\n",
    "        # Each of the 2nd level .zip files has a single file in it with the same name (different file extension)\n",
    "        # Using the .zip file name, generate names for .csv file and table name for GBQ\n",
    "        file_name = name.replace(\".zip\", \".csv\")\n",
    "        my_table = name.replace(\".zip\", \"\")\n",
    "        table_full_name = \".\".join([gbq_proj_id,gbq_dataset_id,my_table])\n",
    "        # Create and ensure emptiness of data frame\n",
    "        df = pd.DataFrame()\n",
    "        df = df[0:0]\n",
    "        # Open 2nd level zip file\n",
    "        with z.open(name) as z2:\n",
    "            z2_filedata = io.BytesIO(z2.read())\n",
    "            # Open 3rd level zipped .csv\n",
    "            with zipfile.ZipFile(z2_filedata) as nested_zip:\n",
    "                temp = nested_zip.open(file_name)\n",
    "                # This code was used to establish whether or not a quote character was needed for the below\n",
    "                # data frame creation. Ended up being superfluous/counterproductive, but preserved just in case.\n",
    "                #first_line = temp.readline().decode(\"utf-8\")\n",
    "                #if first_line[0] == '\"':\n",
    "                #    quotechar_input = '\"'\n",
    "                #else:\n",
    "                #    quotechar_input = None\n",
    "                #\n",
    "                # Determine the delimiter\n",
    "                dialect = csv.Sniffer().sniff(sample = temp.readline().decode(\"utf-8\"),\n",
    "                                      delimiters = [\",\",\";\",\"\\t\"])\n",
    "                delim = dialect.delimiter\n",
    "                # Determine if .csv has headers, used below\n",
    "                # Status of 0 means use the 0 index row of .csv as a header\n",
    "                # Status None means do not use any rows as header\n",
    "                if \"datetime\" in first_line:\n",
    "                    header_status = 0\n",
    "                else:\n",
    "                    header_status = None\n",
    "                # Close .csv\n",
    "                temp.close()\n",
    "                # Write temporary .csv file to be converted to data frame.\n",
    "                # It should theoretically be possible to get the data into a pandas data frame\n",
    "                # without this step, but I couldn't root out the errors that kept cropping up\n",
    "                # Adding this step made it work\n",
    "                pd_input = nested_zip.open(file_name).read().decode(\"utf-8\")\n",
    "                with open (\"clean.csv\", 'w') as out_file:\n",
    "                    out_file.write(pd_input)\n",
    "                # Create pandas dataframe from temporary .csv, specifying header status and delimiter \n",
    "                df = pd.read_csv(open(\"clean.csv\"), header = header_status, sep = delim)\n",
    "                # Assign column names from list above. This makes the headers uniform regardless of\n",
    "                # whether the source .csv had a header or not.\n",
    "                df.columns = col_heads\n",
    "                # Some of the source .csv's have null values that GBQ cannot interpret for columns\n",
    "                # that have a type Boolean, creating errors. By casting these columns as Boolean in\n",
    "                # data frame, they take on values that GBQ can interpret\n",
    "                cols_to_bool = [\"memType\", \"staff\", \"batchHeaderID\", \"display\"]\n",
    "                df[cols_to_bool] = df[cols_to_bool].astype('bool')\n",
    "                # Some of the source .csv's also have null values marked as \\N. This throws errors for\n",
    "                # GBQ for some column types, so this step eliminates them\n",
    "                df = df.replace({r\"\\N\": None})\n",
    "                # Close file\n",
    "                nested_zip.close()\n",
    "        # Upload data frame to GBQ\n",
    "        df.to_gbq(destination_table = table_full_name, \n",
    "                  project_id = gbq_proj_id, \n",
    "                  chunksize = 500000, \n",
    "                  if_exists = \"append\", \n",
    "                  table_schema = wedge_schema,\n",
    "                  credentials = credentials)\n",
    "        # Print .csv name to display which file just finished being uploaded, for monitoring purposes\n",
    "        print(f\"Done with {file_name}.\")\n",
    "# When all loops are completed, and all .csv's have been dealt with, delete the temp .csv that was used above\n",
    "os.remove(\"clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa7a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this whenever the above has finished, whether it was successful or not, to ensure file closure\n",
    "\n",
    "try:\n",
    "    temp.close()\n",
    "    pd_input.close()\n",
    "\n",
    "except:\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
